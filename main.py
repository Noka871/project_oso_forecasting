# main.py
import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import yaml
import warnings

warnings.filterwarnings('ignore')


class OzoneForecaster:
    """
    –ì–∏–±—Ä–∏–¥–Ω–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è
    –æ–±—â–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –æ–∑–æ–Ω–∞ (–û–°–û) —Å —É—á–µ—Ç–æ–º —Å–µ–∑–æ–Ω–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–∏
    –∏ –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏—Ö —Ç—Ä–µ–Ω–¥–æ–≤
    """

    def __init__(self, config_path: str = 'config/config.yaml'):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤—â–∏–∫–∞ –æ–∑–æ–Ω–∞"""
        try:
            with open(config_path, 'r') as file:
                self.config = yaml.safe_load(file)
        except FileNotFoundError:
            print(f"‚ö†Ô∏è  –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_path} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            self.config = {
                'model': {'n_steps': 60},
                'data': {
                    'raw_path': 'data/raw/',
                    'processed_path': 'data/processed/',
                    'ozone_file': 'ozone_data.csv'
                }
            }

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        self.n_steps = self.config['model']['n_steps']
        self.n_features = 12  # 12 –º–µ—Å—è—Ü–µ–≤ –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏
        self.scaler = StandardScaler()
        self.model = None
        self.history = None

    def load_and_preprocess_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö TEMIS –¥–ª—è –¢–æ–º—Å–∫–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
            data_path = os.path.join(self.config['data']['raw_path'], self.config['data']['ozone_file'])

            if os.path.exists(data_path):
                print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {data_path}")
                df = pd.read_csv(data_path, parse_dates=['date'])
            else:
                print("üìä –°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
                df = self._create_synthetic_data()

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                os.makedirs(self.config['data']['raw_path'], exist_ok=True)
                df.to_csv(data_path, index=False)
                print(f"üíæ –î–µ–º–æ-–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {data_path}")

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}. –°–æ–∑–¥–∞—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            df = self._create_synthetic_data()

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df.set_index('date', inplace=True)
        df = self._handle_missing_values(df)

        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(df)} –∑–∞–ø–∏—Å–µ–π, —Å {df.index.min()} –ø–æ {df.index.max()}")
        return df

    def _create_synthetic_data(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∏–º–∏—Ç–∏—Ä—É—é—â–∏—Ö –û–°–û –¥–ª—è –¢–æ–º—Å–∫–∞"""
        print("üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

        dates = pd.date_range('1960-01-01', '2024-12-31', freq='D')
        n = len(dates)

        # –ë–∞–∑–æ–≤—ã–π —Ç—Ä–µ–Ω–¥ - –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –æ–∑–æ–Ω–∞ (–≥–ª–æ–±–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥)
        base_trend = np.linspace(350, 320, n)

        # –°–µ–∑–æ–Ω–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ (—Å–∏–Ω—É—Å–æ–∏–¥–∞ —Å –≥–æ–¥–æ–≤—ã–º –ø–µ—Ä–∏–æ–¥–æ–º)
        seasonal = 25 * np.sin(2 * np.pi * np.arange(n) / 365.25)

        # –ê–Ω–æ–º–∞–ª–∏–∏ –¥–ª—è –æ—Å–µ–Ω–Ω–µ-–∑–∏–º–Ω–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ (—Å 2020 –≥–æ–¥–∞)
        anomaly = np.zeros(n)
        anomaly_mask = (dates >= '2020-09-01')
        anomaly[anomaly_mask] = -10 * np.sin(2 * np.pi * (np.arange(n)[anomaly_mask] % 365.25) / 365.25)

        # –®—É–º
        noise = np.random.normal(0, 5, n)

        # –ò—Ç–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        ozone_data = base_trend + seasonal + anomaly + noise

        # –°–æ–∑–¥–∞–µ–º 12 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–º–µ—Å—è—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        data_dict = {'date': dates, 'ozone': np.clip(ozone_data, 250, 400)}

        # –î–æ–±–∞–≤–ª—è–µ–º 11 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, –≤–ª–∞–∂–Ω–æ—Å—Ç—å, –¥–∞–≤–ª–µ–Ω–∏–µ –∏ —Ç.–¥.)
        for i in range(1, 12):
            # –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å–µ–∑–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
            seasonal_component = 10 * np.sin(2 * np.pi * (np.arange(n) / 365.25 + i / 12))
            trend_component = np.random.normal(0, 2, n)
            data_dict[f'feature_{i}'] = seasonal_component + trend_component + np.random.normal(0, 1, n)

        return pd.DataFrame(data_dict)

    def _handle_missing_values(self, df):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º —Ä—è–¥—É"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏
        missing_count = df.isnull().sum().sum()
        if missing_count > 0:
            print(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ {missing_count} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π...")

        # –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        df_interpolated = df.interpolate(method='time')

        # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –ø—Ä–æ–ø—É—Å–∫–æ–≤
        df_filled = df_interpolated.fillna(df_interpolated.mean())

        return df_filled

    def create_features(self, df, target_column='ozone'):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞"""
        print("üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        df_features = df.copy()

        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df_features['year'] = df_features.index.year
        df_features['month'] = df_features.index.month
        df_features['day_of_year'] = df_features.index.dayofyear
        df_features['day_of_week'] = df_features.index.dayofweek
        df_features['week_of_year'] = df_features.index.isocalendar().week
        df_features['quarter'] = df_features.index.quarter

        # –¢—Ä–∏–≥–æ–Ω–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏
        df_features['month_sin'] = np.sin(2 * np.pi * df_features['month'] / 12)
        df_features['month_cos'] = np.cos(2 * np.pi * df_features['month'] / 12)
        df_features['day_sin'] = np.sin(2 * np.pi * df_features['day_of_year'] / 365.25)
        df_features['day_cos'] = np.cos(2 * np.pi * df_features['day_of_year'] / 365.25)

        # –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        for lag in [1, 2, 3, 7, 14]:
            df_features[f'{target_column}_lag_{lag}'] = df_features[target_column].shift(lag)

        # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        for window in [7, 14, 30]:
            df_features[f'{target_column}_rolling_mean_{window}'] = (
                df_features[target_column].rolling(window=window).mean()
            )
            df_features[f'{target_column}_rolling_std_{window}'] = (
                df_features[target_column].rolling(window=window).std()
            )

        # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å NaN
        initial_count = len(df_features)
        df_features = df_features.dropna()
        final_count = len(df_features)

        print(f"üìä –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã: {initial_count - final_count} —Å—Ç—Ä–æ–∫ —É–¥–∞–ª–µ–Ω–æ –∏–∑-–∑–∞ NaN")
        print(f"üìä –ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df_features.columns)}")

        return df_features

    def prepare_sequences(self, X, y, time_steps=1):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è LSTM"""
        Xs, ys = [], []

        for i in range(len(X) - time_steps):
            Xs.append(X[i:(i + time_steps)])
            ys.append(y[i + time_steps])

        return np.array(Xs), np.array(ys)

    def build_hybrid_model(self, input_shape):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Conv1D + LSTM"""
        print("üîß –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏...")

        model = Sequential([
            # Conv1D —Å–ª–æ–π –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            Conv1D(
                filters=64,
                kernel_size=3,
                activation='relu',
                input_shape=input_shape
            ),

            # LSTM —Å–ª–æ–π –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            LSTM(128, return_sequences=True),
            Dropout(0.3),

            LSTM(64, return_sequences=False),
            Dropout(0.3),

            # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
            Dense(64, activation='relu'),
            Dense(32, activation='relu'),
            Dropout(0.3),

            # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
            Dense(1)
        ])

        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )

        print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞. Input shape: {input_shape}")
        return model

    def train_model(self, df, test_size=0.2):
        """–û–±—É—á–µ–Ω–∏–µ –≥–∏–±—Ä–∏–¥–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df_features = self.create_features(df)

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        X = df_features.drop(columns=['ozone'])
        y = df_features['ozone']

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —É –Ω–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if X.shape[1] < self.n_features:
            print(f"‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}. –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ...")
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —á—Ç–æ–±—ã –¥–æ—Å—Ç–∏—á—å 12
            for i in range(X.shape[1], self.n_features):
                X[f'synthetic_feature_{i}'] = np.random.normal(0, 1, len(X))
        elif X.shape[1] > self.n_features:
            print(f"‚ö†Ô∏è  –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}. –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ {self.n_features}...")
            X = X.iloc[:, :self.n_features]

        print(f"üìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")

        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
        split_idx = int(len(X) * (1 - test_size))
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

        print(f"üìä –î–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã: Train={len(X_train)}, Test={len(X_test)}")

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        X_train_seq, y_train_seq = self.prepare_sequences(
            X_train_scaled, y_train.values, self.n_steps
        )
        X_test_seq, y_test_seq = self.prepare_sequences(
            X_test_scaled, y_test.values, self.n_steps
        )

        print(f"üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: Train={X_train_seq.shape}, Test={X_test_seq.shape}")

        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º input_shape
        input_shape = (self.n_steps, X_train_seq.shape[2])
        self.model = self.build_hybrid_model(input_shape)

        print("üß† –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")
        self.history = self.model.fit(
            X_train_seq, y_train_seq,
            epochs=30,  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            batch_size=32,
            validation_split=0.2,
            verbose=1,
            shuffle=False
        )

        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        return X_test_seq, y_test_seq, X_test, y_test

    def predict(self, X_seq):
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞!")

        print("üîÆ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤...")
        predictions = self.model.predict(X_seq, verbose=0)
        return predictions.flatten()

    def evaluate_model(self, y_true, y_pred):
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏"""
        metrics = {
            'MSE': mean_squared_error(y_true, y_pred),
            'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
            'MAE': mean_absolute_error(y_true, y_pred)
        }

        # R¬≤ score
        ss_res = np.sum((y_true - y_pred) ** 2)
        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
        metrics['R2'] = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

        # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        metrics['MAPE'] = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

        return metrics

    def plot_results(self, df, y_test, y_pred, test_start_idx):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
        print("üìà –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")

        plt.figure(figsize=(15, 12))

        # 1. –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        plt.subplot(3, 1, 1)
        plt.plot(df.index, df['ozone'], 'b-', alpha=0.7, label='–ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ', linewidth=1)
        plt.axvline(x=df.index[test_start_idx], color='r', linestyle='--',
                    label='–ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞')
        plt.title('üìä –û–±—â–µ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –æ–∑–æ–Ω–∞ (–û–°–û) –≤ –¢–æ–º—Å–∫–µ (1960-2024 –≥–≥.)', fontsize=14, fontweight='bold')
        plt.xlabel('–ì–æ–¥')
        plt.ylabel('–û–°–û (–µ–¥. –î–æ–±—Å–æ–Ω–∞)')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # 2. –¢–µ—Å—Ç–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥ —Å –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏
        plt.subplot(3, 1, 2)
        test_dates = df.index[test_start_idx + self.n_steps:test_start_idx + self.n_steps + len(y_pred)]

        plt.plot(test_dates, y_test[:len(y_pred)], 'b-', label='–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è', linewidth=2)
        plt.plot(test_dates, y_pred, 'r--', label='–ü—Ä–æ–≥–Ω–æ–∑ –º–æ–¥–µ–ª–∏', linewidth=2)
        plt.title('üéØ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏', fontsize=12)
        plt.xlabel('–ì–æ–¥')
        plt.ylabel('–û–°–û (–µ–¥. –î–æ–±—Å–æ–Ω–∞)')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # 3. –û—à–∏–±–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞
        plt.subplot(3, 1, 3)
        errors = y_test[:len(y_pred)] - y_pred
        plt.plot(test_dates, errors, 'g-', alpha=0.7, label='–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞')
        plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)
        plt.fill_between(test_dates, errors, 0, alpha=0.3, color='green')
        plt.title('üìâ –û—à–∏–±–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è', fontsize=12)
        plt.xlabel('–ì–æ–¥')
        plt.ylabel('–û—à–∏–±–∫–∞ (–µ–¥. –î–æ–±—Å–æ–Ω–∞)')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.tight_layout()

        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É results –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs('results', exist_ok=True)
        plt.savefig('results/ozone_forecast_results.png', dpi=300, bbox_inches='tight')
        plt.show()

    def plot_training_history(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è"""
        if self.history is None:
            return

        plt.figure(figsize=(12, 4))

        plt.subplot(1, 2, 1)
        plt.plot(self.history.history['loss'], label='Training Loss')
        plt.plot(self.history.history['val_loss'], label='Validation Loss')
        plt.title('–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è - Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.subplot(1, 2, 2)
        plt.plot(self.history.history['mae'], label='Training MAE')
        plt.plot(self.history.history['val_mae'], label='Validation MAE')
        plt.title('–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è - MAE')
        plt.xlabel('Epoch')
        plt.ylabel('MAE')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig('results/training_history.png', dpi=300, bbox_inches='tight')
        plt.show()

    def print_summary_report(self, metrics, df):
        """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –≤ —Ç—Ä–µ–±—É–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        print("\n" + "=" * 80)
        print("üéØ –ú–û–î–ï–õ–ò–†–û–í–ê–ù–ò–ï –ì–ò–ë–†–ò–î–ù–û–ô –ù–ï–ô–†–û–°–ï–¢–ï–í–û–ô –ê–†–•–ò–¢–ï–ö–¢–£–†–´")
        print("   –î–õ–Ø –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø –û–ë–©–ï–ì–û –°–û–î–ï–†–ñ–ê–ù–ò–Ø –û–ó–û–ù–ê")
        print("=" * 80)

        print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø:")
        print("-" * 50)
        print(f"üìç –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã: 56¬∞29'19\" —Å.—à. 84¬∞57'08\" –≤.–¥. (–¢–æ–º—Å–∫)")
        print(f"üìÖ –ü–µ—Ä–∏–æ–¥ –¥–∞–Ω–Ω—ã—Ö: {df.index.min().year} - {df.index.max().year}")
        print(f"üìà –û–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö: {len(df):,} –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π")
        print(f"üîß –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: Conv1D + LSTM + Dense")

        print("\nüìä –ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê –ú–û–î–ï–õ–ò:")
        print("-" * 50)
        print(f"  üìè MSE: {metrics['MSE']:.4f}")
        print(f"  üìê RMSE: {metrics['RMSE']:.4f}")
        print(f"  üìä MAE: {metrics['MAE']:.4f}")
        print(f"  üéØ R¬≤: {metrics['R2']:.4f}")
        print(f"  üìâ MAPE: {metrics['MAPE']:.2f}%")

        print("\nüîç –ö–õ–Æ–ß–ï–í–´–ï –ù–ê–ë–õ–Æ–î–ï–ù–ò–Ø:")
        print("-" * 50)
        print("‚Ä¢ ‚úÖ –í—ã—è–≤–ª–µ–Ω —Ç—Ä–µ–Ω–¥ —Å–Ω–∏–∂–µ–Ω–∏—è –û–°–û –≤ –æ—Å–µ–Ω–Ω–µ-–∑–∏–º–Ω–∏–π –ø–µ—Ä–∏–æ–¥")
        print("‚Ä¢ üìâ –ù–∞–±–ª—é–¥–∞—é—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ —Å 2020 –≥–æ–¥–∞")
        print("‚Ä¢ üîÑ –ú–æ–¥–µ–ª—å —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–µ–∑–æ–Ω–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è –∏ –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–µ —Ç—Ä–µ–Ω–¥—ã")
        print("‚Ä¢ üéØ –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞—É—á–Ω—ã–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º")
        print(f"‚Ä¢ üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {self.n_features}")

        print("\nüåê –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ü–†–û–ï–ö–¢–ï:")
        print("-" * 50)
        print("üìÇ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: https://github.com/Noka871/project_oso_forecasting.git")
        print("üíª –°—Ä–µ–¥–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏: PyCharm, Python 3.10")
        print("üìö –ö–ª—é—á–µ–≤—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: TensorFlow, Keras, Scikit-learn")
        print("üîß –°—Ç–∞—Ç—É—Å: –í –∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ")

        print("\n" + "=" * 80)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ó–ê–ü–£–°–ö –°–ò–°–¢–ï–ú–´ –ü–†–û–ì–ù–û–ó–ò–†–û–í–ê–ù–ò–Ø –°–û–î–ï–†–ñ–ê–ù–ò–Ø –û–ó–û–ù–ê")
    print("=" * 50)

    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤—â–∏–∫–∞
        forecaster = OzoneForecaster()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        df = forecaster.load_and_preprocess_data()

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
        X_test_seq, y_test_seq, X_test, y_test = forecaster.train_model(df)

        if X_test_seq is not None:
            y_pred = forecaster.predict(X_test_seq)

            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            metrics = forecaster.evaluate_model(y_test_seq, y_pred)

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            test_start_idx = int(len(df) * 0.8)
            forecaster.plot_results(df, y_test_seq, y_pred, test_start_idx)
            forecaster.plot_training_history()

            # –í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞
            forecaster.print_summary_report(metrics, df)
        else:
            print("‚ùå –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å")

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        print("üîß –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø—Ä–æ–µ–∫—Ç–∞")


if __name__ == "__main__":
    main()